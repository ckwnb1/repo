{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "Chen Kewen.3036195526"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AKS Cluster Information\n",
    "\n",
    "- **AKS Cluster Name:** assign4-cluster\n",
    "- **Resource Group Name:** assign4-resource-group\n",
    "- **Storage Account Name:** assign4storageaccount\n",
    "- **Blob Container Name:** assign4blobcontainer\n",
    "- **Service Account Name:** assign4serviceaccount\n",
    "- **Spark Image:** spark:v3.1.2-hadoop3.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Information\n",
    "\n",
    "- **Dataset URL:** [https://www.kaggle.com/datasets/bhanupratapbiswas/olympic-data](https://www.kaggle.com/datasets/bhanupratapbiswas/olympic-data)\n",
    "- **Dataset Description:** The Olympic Data dataset from Kaggle is a thorough compilation of historical information on the Olympic Games, including data on athletes, events, and results. This dataset offers insights into the performances of athletes from different nations across various editions of both the Summer and Winter Olympics. It consists of 15 columns and 270,000 rows, with data spanning from 1896 to 2016. However, I have focused on data from the 1956 to 2016 Summer Olympics, as I consider the post-World War II Games more reflective of modern sports and hence more pertinent for analysis. The refined dataset includes 15 columns and 171068 rows.\n",
    "- **Column Descriptions:**\n",
    "  - **ID:** A unique ID assigned to each athlete.\n",
    "  - **Name:** The athlete's full name.\n",
    "  - **Sex:** The gender of the athlete.\n",
    "  - **Age:** The age of the athlete at the time of competition.\n",
    "  - **Height:** The athlete's height measured in centimeters.\n",
    "  - **Weight:** The weight of the athlete in kilograms.\n",
    "  - **Team:** The team or country the athlete represents.\n",
    "  - **NOC:** The National Olympic Committee code for the athlete's country.\n",
    "  - **Games:** The specific edition of the Olympic Games (year and season).\n",
    "  - **Year:** The year when the Olympic Games took place.\n",
    "  - **Season:** Indicates whether the Games were held in summer or winter.\n",
    "  - **City:** The host city for the Olympic Games.\n",
    "  - **Sport:** The sport in which the athlete competes.\n",
    "  - **Event:** The specific event or discipline within the sport.\n",
    "  - **Medal:** The type of medal won by the athlete (Gold, Silver, Bronze).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis Questions\n",
    "\n",
    "1. Distribution and development trends of sports participation between male and female athletes.\n",
    "2. Identification of the sports development and traditional strong events of various countries.\n",
    "3. What are the age, height, and weight patterns for gold medalists in different sports to win the championship?\n",
    "4. Examination of the home advantage phenomenon in the Olympics: Do host countries win significantly more medals compared to the Olympics before and after they host?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_extract,count,when,avg,lag,format_number,concat, lit,row_number,concat_ws,collect_list,expr,greatest\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Height: double (nullable = true)\n",
      " |-- Weight: double (nullable = true)\n",
      " |-- Team: string (nullable = true)\n",
      " |-- NOC: string (nullable = true)\n",
      " |-- Games: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Sport: string (nullable = true)\n",
      " |-- Event: string (nullable = true)\n",
      " |-- Medal: string (nullable = true)\n",
      "\n",
      "+---+------------------+---+----+------+------+-------+---+-----------+----+------+---------+----------+--------------------+-----+\n",
      "| ID|              Name|Sex| Age|Height|Weight|   Team|NOC|      Games|Year|Season|     City|     Sport|               Event|Medal|\n",
      "+---+------------------+---+----+------+------+-------+---+-----------+----+------+---------+----------+--------------------+-----+\n",
      "|  1|         A Dijiang|  M|24.0| 180.0|  80.0|  China|CHN|1992 Summer|1992|Summer|Barcelona|Basketball|Basketball Men's ...|   NA|\n",
      "|  2|          A Lamusi|  M|23.0| 170.0|  60.0|  China|CHN|2012 Summer|2012|Summer|   London|      Judo|Judo Men's Extra-...|   NA|\n",
      "| 12| Jyri Tapani Aalto|  M|31.0| 172.0|  70.0|Finland|FIN|2000 Summer|2000|Summer|   Sydney| Badminton|Badminton Men's S...|   NA|\n",
      "| 13|Minna Maarit Aalto|  F|30.0| 159.0|  55.5|Finland|FIN|1996 Summer|1996|Summer|  Atlanta|   Sailing|Sailing Women's W...|   NA|\n",
      "| 13|Minna Maarit Aalto|  F|34.0| 159.0|  55.5|Finland|FIN|2000 Summer|2000|Summer|   Sydney|   Sailing|Sailing Women's W...|   NA|\n",
      "+---+------------------+---+----+------+------+-------+---+-----------+----+------+---------+----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Athlete Events Data Import\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"Name\", StringType(), True),\n",
    "    StructField(\"Sex\", StringType(), True),\n",
    "    StructField(\"Age\", DoubleType(), True),\n",
    "    StructField(\"Height\", DoubleType(), True),\n",
    "    StructField(\"Weight\", DoubleType(), True),\n",
    "    StructField(\"Team\", StringType(), True),\n",
    "    StructField(\"NOC\", StringType(), True),\n",
    "    StructField(\"Games\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Season\", StringType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"Sport\", StringType(), True),\n",
    "    StructField(\"Event\", StringType(), True),\n",
    "    StructField(\"Medal\", StringType(), True)\n",
    "])\n",
    "\n",
    "# File path\n",
    "csv_file_path = \"E:/hku/cloud cluster/ex4/dataset/athlete_events.csv\"\n",
    "\n",
    "# Read CSV file\n",
    "spark_df = spark.read.csv(csv_file_path, schema=schema, header=True)\n",
    "\n",
    "# Filter data\n",
    "spark_df = spark_df.filter((spark_df.Games.contains('Summer')) & (spark_df.Year >= 1956))\n",
    "\n",
    "# Print schema\n",
    "spark_df.printSchema()\n",
    "\n",
    "# Show first 5 rows\n",
    "spark_df.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA1: Distribution and development trends of sports participation between male and female athletes\n",
    "1. Calculate the number of male and female athletes participating in each Olympic Games \n",
    "2. Calculate the growth rate and ratio of female participants in each Olympic Games\n",
    "Group by gender and year, and count the number of athletes in each group\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----------------+\n",
      "|Sex|Year|Participant_Count|\n",
      "+---+----+-----------------+\n",
      "|  F|1956|              891|\n",
      "|  M|1956|             4208|\n",
      "|  F|1960|             1422|\n",
      "|  M|1960|             6660|\n",
      "|  F|1964|             1336|\n",
      "|  M|1964|             6326|\n",
      "|  F|1968|             1767|\n",
      "|  M|1968|             6786|\n",
      "|  F|1972|             2179|\n",
      "|  M|1972|             8090|\n",
      "|  F|1976|             2164|\n",
      "|  M|1976|             6457|\n",
      "|  F|1980|             1755|\n",
      "|  M|1980|             5435|\n",
      "|  F|1984|             2442|\n",
      "|  M|1984|             6984|\n",
      "|  F|1988|             3535|\n",
      "|  M|1988|             8473|\n",
      "|  F|1992|             4114|\n",
      "|  M|1992|             8832|\n",
      "|  F|1996|             4998|\n",
      "|  M|1996|             8760|\n",
      "|  F|2000|             5430|\n",
      "|  M|2000|             8386|\n",
      "|  F|2004|             5545|\n",
      "|  M|2004|             7895|\n",
      "|  F|2008|             5816|\n",
      "|  M|2008|             7783|\n",
      "|  F|2012|             5815|\n",
      "|  M|2012|             7099|\n",
      "|  F|2016|             6223|\n",
      "|  M|2016|             7462|\n",
      "+---+----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Group by gender and year, and count the number of athletes in each group\n",
    "gender_trend_df = spark_df.groupBy(\"Sex\", \"Year\").agg(count(\"ID\").alias(\"Participant_Count\"))\n",
    "#  Sort the result\n",
    "sorted_gender_trend_df = gender_trend_df.orderBy(\"Year\", \"Sex\")\n",
    "# Show the first 20 rows\n",
    "sorted_gender_trend_df.show(40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Group by gender and year, and count the number of athletes in each group\n",
    "gender_trend_df = spark_df.groupBy(\"Sex\", \"Year\").agg(\n",
    "    count(\"ID\").alias(\"Participant_Count\")\n",
    ")\n",
    "# Calculate annual growth rate and participation ratio\n",
    "window_spec = Window.partitionBy(\"Sex\").orderBy(\"Year\")\n",
    "gender_trend_df = gender_trend_df.withColumn(\n",
    "    \"Prev_Year_Participant\", lag(\"Participant_Count\").over(window_spec)\n",
    ").withColumn(\n",
    "    \"Growth_Rate\", \n",
    "    ((col(\"Participant_Count\") - col(\"Prev_Year_Participant\")) / col(\"Prev_Year_Participant\") * 100).cast(\"decimal(10,3)\")\n",
    ").withColumn(\n",
    "    \"Growth_Rate\", concat(col(\"Growth_Rate\"), lit(\"%\"))\n",
    ")\n",
    "#Calculate the total number of participants and participation ratio each year\n",
    "total_participants_df = spark_df.groupBy(\"Year\").agg(count(\"ID\").alias(\"Total_Participants\"))\n",
    "gender_ratio_df = gender_trend_df.join(total_participants_df, on=\"Year\").withColumn(\n",
    "    \"Participation_Ratio\", (col(\"Participant_Count\") / col(\"Total_Participants\") * 100).cast(\"decimal(10,3)\")\n",
    ").withColumn(\n",
    "    \"Participation_Ratio\", concat(col(\"Participation_Ratio\"), lit(\"%\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+-----------------+---------------------+-----------+------------------+-------------------+\n",
      "|Year|Sex|Participant_Count|Prev_Year_Participant|Growth_Rate|Total_Participants|Participation_Ratio|\n",
      "+----+---+-----------------+---------------------+-----------+------------------+-------------------+\n",
      "|1956|F  |891              |NULL                 |NULL       |5099              |17.474%            |\n",
      "|1956|M  |4208             |NULL                 |NULL       |5099              |82.526%            |\n",
      "|1960|F  |1422             |891                  |59.596%    |8082              |17.595%            |\n",
      "|1960|M  |6660             |4208                 |58.270%    |8082              |82.405%            |\n",
      "|1964|F  |1336             |1422                 |-6.048%    |7662              |17.437%            |\n",
      "|1964|M  |6326             |6660                 |-5.015%    |7662              |82.563%            |\n",
      "|1968|F  |1767             |1336                 |32.260%    |8553              |20.659%            |\n",
      "|1968|M  |6786             |6326                 |7.272%     |8553              |79.341%            |\n",
      "|1972|F  |2179             |1767                 |23.316%    |10269             |21.219%            |\n",
      "|1972|M  |8090             |6786                 |19.216%    |10269             |78.781%            |\n",
      "|1976|F  |2164             |2179                 |-0.688%    |8621              |25.101%            |\n",
      "|1976|M  |6457             |8090                 |-20.185%   |8621              |74.899%            |\n",
      "|1980|F  |1755             |2164                 |-18.900%   |7190              |24.409%            |\n",
      "|1980|M  |5435             |6457                 |-15.828%   |7190              |75.591%            |\n",
      "|1984|F  |2442             |1755                 |39.145%    |9426              |25.907%            |\n",
      "|1984|M  |6984             |5435                 |28.500%    |9426              |74.093%            |\n",
      "|1988|F  |3535             |2442                 |44.758%    |12008             |29.439%            |\n",
      "|1988|M  |8473             |6984                 |21.320%    |12008             |70.561%            |\n",
      "|1992|F  |4114             |3535                 |16.379%    |12946             |31.778%            |\n",
      "|1992|M  |8832             |8473                 |4.237%     |12946             |68.222%            |\n",
      "|1996|F  |4998             |4114                 |21.488%    |13758             |36.328%            |\n",
      "|1996|M  |8760             |8832                 |-0.815%    |13758             |63.672%            |\n",
      "|2000|F  |5430             |4998                 |8.643%     |13816             |39.302%            |\n",
      "|2000|M  |8386             |8760                 |-4.269%    |13816             |60.698%            |\n",
      "|2004|F  |5545             |5430                 |2.118%     |13440             |41.257%            |\n",
      "|2004|M  |7895             |8386                 |-5.855%    |13440             |58.743%            |\n",
      "|2008|F  |5816             |5545                 |4.887%     |13599             |42.768%            |\n",
      "|2008|M  |7783             |7895                 |-1.419%    |13599             |57.232%            |\n",
      "|2012|F  |5815             |5816                 |-0.017%    |12914             |45.029%            |\n",
      "|2012|M  |7099             |7783                 |-8.788%    |12914             |54.971%            |\n",
      "|2016|F  |6223             |5815                 |7.016%     |13685             |45.473%            |\n",
      "|2016|M  |7462             |7099                 |5.113%     |13685             |54.527%            |\n",
      "+----+---+-----------------+---------------------+-----------+------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show all data\n",
    "gender_ratio_df.orderBy(\"Year\", \"Sex\").show(n=200000, truncate=False)\n",
    "gender_ratio_df.orderBy(\"Year\", \"Sex\").write.csv(\"E:/hku/cloud cluster/ex4/output/eda1_gender_ratio.csv\", header=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Inference\n",
    "\n",
    "Since 1956, the number and proportion of female athletes have steadily increased, with the number rising from 891 in 1956 to 7462 in 2016, and the proportion rising from 17% in 1956 to 45% in 2016 (approaching gender balance). It is inferred that this trend is related to the advancement of gender equality and women's rights movements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Action Operation: `gender_trend_df.withColumn(...)`\n",
    "\n",
    "### Analysis of the Spark Job for `gender_trend_df.withColumn(...)`\n",
    "\n",
    "#### Action Operation\n",
    "```python\n",
    "window_spec = Window.partitionBy(\"Sex\").orderBy(\"Year\")\n",
    "gender_trend_df = gender_trend_df.withColumn(\n",
    "    \"Prev_Year_Participant\", lag(\"Participant_Count\").over(window_spec)\n",
    ").withColumn(\n",
    "    \"Growth_Rate\", \n",
    "    ((col(\"Participant_Count\") - col(\"Prev_Year_Participant\")) / col(\"Prev_Year_Participant\") * 100).cast(\"decimal(10,3)\")\n",
    ").withColumn(\n",
    "    \"Growth_Rate\", concat(col(\"Growth_Rate\"), lit(\"%\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution Plan Analysis\n",
    "\n",
    "The Spark job for gender_trend_df.withColumn(...) involves the following stages:\n",
    "\n",
    "    Stage 1:\n",
    "        Operation: Read data from the CSV file and count the number of participants by Sex and Year.\n",
    "        Details: This stage involves reading the data and performing a group-by operation to count the participants. This group-by operation requires the data to be repartitioned by Sex and Year, which results in a shuffle event.\n",
    "\n",
    "    Stage 2:\n",
    "        Operation: Apply the window function to compute the previous year's participant count.\n",
    "        Details: In this stage, a window function is applied to compute the participant count for the previous year. This operation requires sorting the data, which results in another shuffle event.\n",
    "\n",
    "Summary\n",
    "\n",
    "In the analysis of the gender_trend_df.withColumn(...) Spark job, the job is divided into two main stages. The first stage reads the data from the CSV file and counts the number of participants by gender and year, which triggers the first shuffle event due to the group-by operation. The second stage applies a window function to compute the previous year's participant count and calculates the growth rate, triggering a second shuffle event due to the sorting requirement. The execution plan clearly shows the specific operations in each stage and the reasons for the shuffle events, helping us understand the job's execution process and identify potential areas for performance optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA2: Identification of the sports infrastructure and traditional strong events of various countries\n",
    "Idea: Track the change in the total number of medals over time for each country  2. Filter the leading countries in each sport and finally merge them. \n",
    "For example, if France is the leading country in both sport1 and sport2, \n",
    "the result will show France: sport1, sport2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------------------------------------------------+\n",
      "|Year|Top10Countries                                                                     |\n",
      "+----+-----------------------------------------------------------------------------------+\n",
      "|1956|URS-169, USA-111, AUS-67, HUN-64, GER-52, ITA-47, GBR-46, SWE-34, FRA-33, FIN-26   |\n",
      "|1960|URS-169, USA-118, ITA-88, GER-88, HUN-66, AUS-46, JPN-31, POL-30, GBR-28, DEN-23   |\n",
      "|1964|URS-174, USA-153, GER-116, JPN-62, HUN-56, TCH-54, ITA-51, POL-46, AUS-44, FRA-31  |\n",
      "|1968|URS-192, USA-156, HUN-81, JPN-63, GDR-52, FRG-51, AUS-51, POL-37, ITA-33, YUG-29   |\n",
      "|1972|URS-214, USA-167, GDR-151, FRG-102, HUN-81, JPN-56, POL-46, ROU-40, TCH-29, GBR-29 |\n",
      "|1976|URS-286, GDR-195, USA-156, FRG-77, POL-73, ROU-55, HUN-55, JPN-41, BUL-39, GBR-32  |\n",
      "|1980|URS-442, GDR-264, BUL-90, ROU-68, HUN-61, YUG-57, TCH-51, POL-50, GBR-47, ITA-37   |\n",
      "|1984|USA-339, FRG-158, ROU-106, YUG-87, CAN-85, CHN-74, GBR-71, FRA-67, ITA-63, AUS-52  |\n",
      "|1988|URS-300, USA-196, GDR-181, FRG-115, KOR-77, YUG-63, ROU-58, GBR-53, CHN-52, NED-45 |\n",
      "|1992|EUN-220, USA-215, GER-198, CHN-82, ESP-69, CUB-69, FRA-57, AUS-57, ROU-53, GBR-50  |\n",
      "|1996|USA-248, AUS-132, GER-124, RUS-115, CHN-106, NED-73, ITA-71, ESP-66, KOR-66, BRA-63|\n",
      "|2000|USA-241, RUS-187, AUS-183, GER-118, CHN-79, NED-79, KOR-73, FRA-66, ITA-65, CUB-65 |\n",
      "|2004|USA-262, RUS-189, AUS-157, GER-149, ITA-104, CHN-94, JPN-93, NED-77, CUB-62, GBR-57|\n",
      "|2008|USA-317, CHN-184, AUS-149, RUS-142, GER-99, GBR-81, BRA-78, KOR-78, FRA-77, ESP-70 |\n",
      "|2012|USA-247, RUS-140, GBR-126, CHN-125, AUS-114, GER-94, JPN-84, FRA-82, NED-69, ITA-68|\n",
      "|2016|USA-263, GER-159, GBR-145, RUS-115, CHN-113, FRA-96, AUS-82, ITA-72, CAN-69, JPN-64|\n",
      "+----+-----------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of medals each country has won every year\n",
    "medal_counts = spark_df.groupBy(\"Year\", \"NOC\").agg(count(when(col(\"Medal\") != 'NA', 1)).alias(\"MedalCount\"))\n",
    "\n",
    "# Use window function to find the top 10 countries with the most medals each year\n",
    "windowSpec = Window.partitionBy(\"Year\").orderBy(col(\"MedalCount\").desc())\n",
    "top_10_countries = medal_counts.withColumn(\"rank\", row_number().over(windowSpec)).filter(col(\"rank\") <= 10).drop(\"rank\")\n",
    "\n",
    "# Display the results as the top 10 countries with the most medals and the corresponding number of medals each year\n",
    "result = top_10_countries.groupBy(\"Year\").agg(concat_ws(\", \", collect_list(concat_ws(\"-\", col(\"NOC\"), col(\"MedalCount\")))).alias(\"Top10Countries\"))\n",
    "# Show results\n",
    "result.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|NOC|DominantSports                                                                                                                                                                                                |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|POL|Weightlifting-113                                                                                                                                                                                             |\n",
      "|BRA|Football-295, Volleyball-285                                                                                                                                                                                  |\n",
      "|CUB|Baseball-112                                                                                                                                                                                                  |\n",
      "|FRA|Judo-135                                                                                                                                                                                                      |\n",
      "|ITA|Fencing-465, Water Polo-244                                                                                                                                                                                   |\n",
      "|GBR|Sailing-212                                                                                                                                                                                                   |\n",
      "|FIJ|Rugby Sevens-26                                                                                                                                                                                               |\n",
      "|AUS|Cycling-379, Hockey-381, Taekwondo-22                                                                                                                                                                         |\n",
      "|HUN|Canoeing-280, Modern Pentathlon-77                                                                                                                                                                            |\n",
      "|USA|Athletics-1774, Basketball-291, Beach Volleyball-51, Boxing-152, Diving-171, Equestrianism-320, Gymnastics-1129, Rowing-591, Shooting-325, Softball-60, Swimming-1262, Tennis-107, Triathlon-29, Wrestling-259|\n",
      "|KOR|Archery-102, Golf-6, Handball-228, Table Tennis-101                                                                                                                                                           |\n",
      "|RUS|Trampolining-16                                                                                                                                                                                               |\n",
      "|ESP|Rhythmic Gymnastics-49                                                                                                                                                                                        |\n",
      "|CHN|Badminton-129                                                                                                                                                                                                 |\n",
      "|JPN|Synchronized Swimming-78                                                                                                                                                                                      |\n",
      "+---+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of medals each country has won in each sport\n",
    "sport_leaders = spark_df.groupBy(\"NOC\", \"Sport\").agg(count(when(col(\"Medal\") != 'Na', 1)).alias(\"MedalCount\"))\n",
    "\n",
    "# Find the leading country in each sport\n",
    "windowSpec = Window.partitionBy(\"Sport\").orderBy(col(\"MedalCount\").desc())\n",
    "sport_leaders = sport_leaders.withColumn(\"rank\", row_number().over(windowSpec)).filter(col(\"rank\") == 1).drop(\"rank\")\n",
    "\n",
    "# Merge all leading sports of the same country\n",
    "merged_sport_leaders = sport_leaders.groupBy(\"NOC\").agg(concat_ws(\", \", collect_list(concat_ws(\"-\", col(\"Sport\"), col(\"MedalCount\")))).alias(\"DominantSports\"))\n",
    "\n",
    "# Show results\n",
    "merged_sport_leaders.show(40, truncate=False)\n",
    "\n",
    "# Save results\n",
    "result.write.csv(\"E:/hku/cloud cluster/ex4/output/eda2_top10_countries.csv\", header=True)\n",
    "merged_sport_leaders.write.csv(\"E:/hku/cloud cluster/ex4/output/eda2_dominant_sports.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "In terms of total medal count, the United States and the Soviet Union have long dominated the top two positions. From 1956 to 1984, the Soviet Union held the advantage, while the United States has consistently held the advantage since 1984, reflecting the gradual decline of the Soviet Union. The United States excels in various ball sports, swimming, and athletics, whereas the Soviet Union had dominance in strength-based events such as gymnastics, volleyball, and wrestling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the Spark Jobs\n",
    "\n",
    "Based on the provided code and the parsed physical plan, we can identify multiple Spark jobs. Specifically, we have two main tasks:\n",
    "\n",
    "    Tracking the Change in Medal Counts Over Time:\n",
    "        Calculate the total number of medals for each country per year.\n",
    "        Use window functions to identify the top 10 countries by medal count each year.\n",
    "        Display the results as the top 10 countries and their corresponding medal counts each year.\n",
    "        This involves a primary Spark job.\n",
    "\n",
    "    Identifying Dominant Countries in Each Sport:\n",
    "        Calculate the total number of medals for each country in each sport.\n",
    "        Use window functions to identify the leading country in each sport.\n",
    "        Merge the dominant sports for each country into a single list.\n",
    "        This also involves a primary Spark job.\n",
    "\n",
    "Detailed Analysis of the Most Critical Spark Job\n",
    "\n",
    "Let's assume that identifying the dominant countries in each sport is the most critical Spark job. Here's a detailed analysis of this job:\n",
    "\n",
    "    First Stage:\n",
    "        Operation: Filter the dataset to include only Summer Olympics and years after 1956.\n",
    "        Description: This stage applies filtering conditions to limit the dataset to relevant records.\n",
    "\n",
    "    Second Stage:\n",
    "        Operation: Aggregate the data to count the number of medals for each country in each sport.\n",
    "        Description: This aggregation calculates the medal count for each country-sport combination.\n",
    "        Shuffle Event: A shuffle occurs here because the data needs to be repartitioned based on the country and sport columns.\n",
    "\n",
    "    Third Stage:\n",
    "        Operation: Sort the aggregated data by sport and medal count.\n",
    "        Description: This stage sorts the data to prepare for ranking within each sport.\n",
    "        Shuffle Event: Another shuffle happens here as data is repartitioned based on the sport and medal count columns.\n",
    "\n",
    "    Fourth Stage:\n",
    "        Operation: Apply window functions to rank the countries within each sport by their medal counts.\n",
    "        Description: This stage uses the row_number() window function to rank countries and identify the top country in each sport.\n",
    "\n",
    "    Fifth Stage:\n",
    "        Operation: Filter to retain only the top-ranked country for each sport.\n",
    "        Description: This final filtering stage keeps only the leading country for each sport.\n",
    "\n",
    "Summary Paragraph\n",
    "\n",
    "In this analysis, we delved into the Olympic dataset to identify the dominant countries in various sports. First, we filtered the data to focus on the Summer Olympics and records from 1956 onwards. Next, we calculated the number of medals each country won in each sport, which triggered a shuffle event as the data had to be reorganized based on country and sport. We then sorted the data by sport and medal count, leading to another shuffle event. Following this, we applied window functions to rank the countries within each sport by their medal counts and filtered the results to retain only the top country for each sport. Finally, we merged the dominant sports for each country into a single list. This critical Spark job involved multiple stages and shuffle events, reflecting the complexity of the analysis.\n",
    "\n",
    "This summary describes the most critical Spark job's stages, the shuffle events, and the key operations performed at each stage. If you have further questions or need additional details, please let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# EDA3: The Relationship Between Height Vs Weight Vs Age of Participants Across Sports\n",
    " Analyze the distribution of winning age, height, and weight in various sports. \n",
    " In other words, divide the age into intervals from 10 to 80, every 5 years, 10-15, 15-20.....,\n",
    " and the height and weight into different intervals.\n",
    " The final result is similar to: Sport1, the most winning age interval, the most winning weight interval, the most winning height interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+----------+----------+\n",
      "|               Sport|Age_Bin|Height_Bin|Weight_Bin|\n",
      "+--------------------+-------+----------+----------+\n",
      "|             Archery|  20-25|   165-170|     70-80|\n",
      "|           Athletics|  20-25|   180-185|     60-70|\n",
      "|           Badminton|  25-30|   175-180|     60-70|\n",
      "|            Baseball|  25-30|   185-190|     80-90|\n",
      "|          Basketball|  20-25|   190-195|    90-100|\n",
      "|    Beach Volleyball|  30-35|   190-195|     70-80|\n",
      "|              Boxing|  20-25|   165-170|     60-70|\n",
      "|            Canoeing|  20-25|   180-185|     80-90|\n",
      "|             Cycling|  20-25|   180-185|     70-80|\n",
      "|              Diving|  20-25|   160-165|     50-60|\n",
      "|       Equestrianism|  30-35|   170-175|     60-70|\n",
      "|             Fencing|  25-30|   175-180|     70-80|\n",
      "|            Football|  20-25|   170-175|     70-80|\n",
      "|                Golf|  25-30|   165-170|     60-70|\n",
      "|          Gymnastics|  20-25|   160-165|     50-60|\n",
      "|            Handball|  25-30|   180-185|     70-80|\n",
      "|              Hockey|  25-30|   170-175|     60-70|\n",
      "|                Judo|  20-25|   170-175|     60-70|\n",
      "|   Modern Pentathlon|  25-30|   180-185|     70-80|\n",
      "| Rhythmic Gymnastics|  15-20|   175-180|     50-60|\n",
      "|              Rowing|  25-30|   190-195|    90-100|\n",
      "|        Rugby Sevens|  20-25|   165-170|     60-70|\n",
      "|             Sailing|  25-30|   180-185|     70-80|\n",
      "|            Shooting|  25-30|   175-180|     70-80|\n",
      "|            Softball|  25-30|   165-170|     60-70|\n",
      "|            Swimming|  20-25|   180-185|     60-70|\n",
      "|Synchronized Swim...|  20-25|   170-175|     50-60|\n",
      "|        Table Tennis|  20-25|   165-170|     60-70|\n",
      "|           Taekwondo|  20-25|   180-185|     50-60|\n",
      "|              Tennis|  25-30|   190-195|     80-90|\n",
      "|        Trampolining|  20-25|   170-175|     50-60|\n",
      "|           Triathlon|  30-35|   180-185|     70-80|\n",
      "|          Volleyball|  25-30|   180-185|     70-80|\n",
      "|          Water Polo|  25-30|   185-190|    90-100|\n",
      "|       Weightlifting|  20-25|   170-175|     50-60|\n",
      "|           Wrestling|  25-30|   170-175|     60-70|\n",
      "+--------------------+-------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a general bin function\n",
    "def create_bin(column, bins, labels):\n",
    "    bin_expr = F.when((column >= bins[0]) & (column < bins[1]), labels[0])\n",
    "    for i in range(1, len(bins) - 1):\n",
    "        bin_expr = bin_expr.when((column >= bins[i]) & (column < bins[i+1]), labels[i])\n",
    "    return bin_expr\n",
    "\n",
    "# Define bins and labels\n",
    "age_bins = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80]\n",
    "age_labels = [\"10-15\", \"15-20\", \"20-25\", \"25-30\", \"30-35\", \"35-40\", \"40-45\", \"45-50\", \"50-55\", \"55-60\", \"60-65\", \"65-70\", \"70-75\", \"75-80\"]\n",
    "\n",
    "height_bins = [120, 125, 130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190, 195, 200, 205, 210, 215, 220]\n",
    "height_labels = [\"120-125\", \"125-130\", \"130-135\", \"135-140\", \"140-145\", \"145-150\", \"150-155\", \"155-160\", \"160-165\", \"165-170\", \"170-175\", \"175-180\", \"180-185\", \"185-190\", \"190-195\", \"195-200\", \"200-205\", \"205-210\", \"210-215\", \"215-220\"]\n",
    "\n",
    "weight_bins = [30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n",
    "weight_labels = [\"30-40\", \"40-50\", \"50-60\", \"60-70\", \"70-80\", \"80-90\", \"90-100\", \"100-110\", \"110-120\", \"120-130\", \"130-140\", \"140-150\"]\n",
    "\n",
    "# Add bin columns\n",
    "spark_df = spark_df.withColumn(\"Age_Bin\", create_bin(F.col(\"Age\"), age_bins, age_labels))\n",
    "spark_df = spark_df.withColumn(\"Height_Bin\", create_bin(F.col(\"Height\"), height_bins, height_labels))\n",
    "spark_df = spark_df.withColumn(\"Weight_Bin\", create_bin(F.col(\"Weight\"), weight_bins, weight_labels))\n",
    "\n",
    "# Filter out gold medalists\n",
    "gold_medalists = spark_df.filter(spark_df[\"Medal\"] == \"Gold\")\n",
    "\n",
    "# Group statistics for the most winning age interval, height interval, and weight interval in different sports\n",
    "age_mode = gold_medalists.groupBy(\"Sport\", \"Age_Bin\").count().withColumnRenamed(\"count\", \"Age_Count\")\n",
    "height_mode = gold_medalists.groupBy(\"Sport\", \"Height_Bin\").count().withColumnRenamed(\"count\", \"Height_Count\")\n",
    "weight_mode = gold_medalists.groupBy(\"Sport\", \"Weight_Bin\").count().withColumnRenamed(\"count\", \"Weight_Count\")\n",
    "\n",
    "# Find the most winning age interval for each sport\n",
    "age_mode = age_mode.withColumn(\"Row_Number\", F.row_number().over(Window.partitionBy(\"Sport\").orderBy(F.desc(\"Age_Count\"))))\n",
    "age_mode = age_mode.filter(age_mode[\"Row_Number\"] == 1).drop(\"Row_Number\")\n",
    "\n",
    "# Find the most winning height interval for each sport\n",
    "height_mode = height_mode.withColumn(\"Row_Number\", F.row_number().over(Window.partitionBy(\"Sport\").orderBy(F.desc(\"Height_Count\"))))\n",
    "height_mode = height_mode.filter(height_mode[\"Row_Number\"] == 1).drop(\"Row_Number\")\n",
    "\n",
    "# Find the most winning weight interval for each sport\n",
    "weight_mode = weight_mode.withColumn(\"Row_Number\", F.row_number().over(Window.partitionBy(\"Sport\").orderBy(F.desc(\"Weight_Count\"))))\n",
    "weight_mode = weight_mode.filter(weight_mode[\"Row_Number\"] == 1).drop(\"Row_Number\")\n",
    "\n",
    "# Merge results\n",
    "result = age_mode.join(height_mode, on=\"Sport\").join(weight_mode, on=\"Sport\")\n",
    "\n",
    "# Select and rename required columns\n",
    "result = result.select(\"Sport\", \"Age_Bin\", \"Height_Bin\", \"Weight_Bin\")\n",
    "result.show(200)\n",
    "# Write EDA3 results to file\n",
    "result.write.csv(\"E:/hku/cloud cluster/ex4/output/eda3_height_weight_age.csv\", header=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "For the majority of Olympic events, gold medalists are typically within the age ranges of 20-25 and 25-30, likely because 20-30 is the peak period for human physical performance. However, there are exceptions: the gold medal age range for Rhythmic Gymnastics is 15-20, and for Beach Volleyball, it is 30-35. This could be due to several reasons:\n",
    "\n",
    "- **Physical demands of gymnastics:**\n",
    "    - **Flexibility:** Gymnastics requires high levels of flexibility and agility, areas where younger athletes often have a distinct advantage.\n",
    "    - **Strength and explosiveness:** Young athletes typically have optimal muscle strength and explosiveness, necessary for performing complex movements.\n",
    "    - **Weight and body composition:** A smaller body weight and compact physique help athletes execute intricate aerial maneuvers and reduce injury risk.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the Spark Jobs\n",
    "\n",
    "Based on the provided code and the parsed physical plan, we can identify multiple Spark jobs. Specifically, we have 3 main tasks:\n",
    "\n",
    "1. Adding bin columns (`Age_Bin`, `Height_Bin`, `Weight_Bin`).\n",
    "2. Grouping statistics for the most winning age interval, height interval, and weight interval.\n",
    "3. Merging results for the final output.\n",
    "\n",
    "Detailed Analysis of the Most Critical Spark Job\n",
    "\n",
    "Let's assume that grouping statistics for the most winning intervals is the most critical Spark job. Here's a detailed analysis of this job:\n",
    "\n",
    "First Stage:\n",
    "- Operation: `groupBy(\"Sport\", \"Age_Bin\").count()`\n",
    "- Description: This operation groups the gold medalists by sport and age bin, then counts the number of occurrences in each group.\n",
    "- Shuffle Event: This stage involves a shuffle because `groupBy` operation requires data to be redistributed across the cluster to ensure that all rows with the same key (Sport, Age_Bin) end up in the same partition.\n",
    "\n",
    "Second Stage:\n",
    "- Operation: `groupBy(\"Sport\", \"Height_Bin\").count()`\n",
    "- Description: Similar to the first stage, this operation groups the data by sport and height bin and counts the occurrences.\n",
    "- Shuffle Event: Again, a shuffle occurs due to the `groupBy` operation.\n",
    "\n",
    "Third Stage:\n",
    "- Operation: `groupBy(\"Sport\", \"Weight_Bin\").count()`\n",
    "- Description: This stage groups the data by sport and weight bin and counts the occurrences.\n",
    "- Shuffle Event: This stage also triggers a shuffle event due to the `groupBy` operation.\n",
    "\n",
    "Fourth Stage:\n",
    "- Operation: `withColumn(\"Row_Number\", F.row_number().over(Window.partitionBy(\"Sport\").orderBy(F.desc(\"Age_Count\"))))`\n",
    "- Description: This operation calculates the row number for each group partitioned by sport and ordered by the descending age count.\n",
    "- Shuffle Event: This operation may trigger a shuffle if the data needs to be repartitioned for window functions.\n",
    "\n",
    "Fifth Stage:\n",
    "- Operation: `filter(age_mode[\"Row_Number\"] == 1)`\n",
    "- Description: Filters the result to keep only the rows with the highest count for each sport in the age bin.\n",
    "- Shuffle Event: This operation may trigger a shuffle depending on how the filtering is implemented.\n",
    "\n",
    "Summary Paragraph\n",
    "\n",
    "The critical Spark job involves multiple stages, each performing essential operations to group and count data based on different bins (age, height, weight) and sports. The key operations are `groupBy` and `count`, which trigger shuffle events to redistribute data across the cluster. Additional operations like `withColumn` for row numbering and filtering to keep the highest counts also contribute to the job's complexity. Understanding these stages helps optimize performance and ensures efficient data processing in PySpark for exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA4: Do host countries win significantly more medals compared to the Olympics before and after they host?\n",
    " Compare the total number of medals won by host countries during the host period and non-host periods. \n",
    " Only compare the host period with the two previous and two subsequent Olympics. \n",
    " Add a new column showing the percentage increase in medals won during the host period compared to the maximum number of medals won during the four non-host periods.\n",
    " Assume you have created SparkSession and imported spark_df\n",
    " spark = SparkSession.builder.appName(\"Olympic Analysis\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+---------------+---------------+---------------+---------------+-------------------+\n",
      "|Year|Country|Medals_host|Medals_nothost1|Medals_nothost2|Medals_nothost3|Medals_nothost4|     Medals_bigger%|\n",
      "+----+-------+-----------+---------------+---------------+---------------+---------------+-------------------+\n",
      "|1956|    AUS|         67|              0|              0|             46|             44| 31.343283582089555|\n",
      "|1960|    ITA|         88|             47|              0|             51|             33|  42.04545454545455|\n",
      "|1964|    JPN|         62|             31|             24|             63|             56|-1.6129032258064515|\n",
      "|1968|    MEX|          9|              1|              1|              1|              2|  77.77777777777779|\n",
      "|1972|    FRG|        102|             51|              0|             77|              0| 24.509803921568626|\n",
      "|1976|    CAN|         23|             11|             10|              0|             85| -269.5652173913044|\n",
      "|1980|    URS|        442|            286|            214|              0|            300| 32.126696832579185|\n",
      "|1984|    USA|        339|              0|            156|            196|            215|  36.57817109144543|\n",
      "|1988|    KOR|         77|             41|              0|             49|             66| 14.285714285714285|\n",
      "|1992|    ESP|         69|              5|             19|             66|             42| 4.3478260869565215|\n",
      "|1996|    USA|        248|            215|            196|            241|            262|  -5.64516129032258|\n",
      "|2000|    AUS|        183|            132|             57|            157|            149| 14.207650273224044|\n",
      "|2004|    GRE|         31|             18|              8|              7|              3| 41.935483870967744|\n",
      "|2008|    CHN|        184|             94|             79|            125|            113| 32.065217391304344|\n",
      "|2012|    GBR|        126|             81|             57|            145|              0|-15.079365079365079|\n",
      "|2016|    BRA|         50|             59|             78|              0|              0| -56.00000000000001|\n",
      "+----+-------+-----------+---------------+---------------+---------------+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter records with medals\n",
    "medals_df = spark_df.filter(col(\"Medal\") != 'NA')\n",
    "\n",
    "# Initialize host countries dictionary\n",
    "host_countries = {\n",
    "    1956: 'AUS', 1960: 'ITA', 1964: 'JPN', 1968: 'MEX', 1972: 'FRG', 1976: 'CAN',\n",
    "    1980: 'URS', 1984: 'USA', 1988: 'KOR', 1992: 'ESP', 1996: 'USA', 2000: 'AUS',\n",
    "    2004: 'GRE', 2008: 'CHN', 2012: 'GBR', 2016: 'BRA'\n",
    "}\n",
    "\n",
    "# Create a temporary view for SQL queries\n",
    "medals_df.createOrReplaceTempView(\"medals\")\n",
    "\n",
    "# Result list\n",
    "results = []\n",
    "\n",
    "# Calculate the number of medals won by the host country during the host period and the two previous and two subsequent Olympics\n",
    "for year, country in host_countries.items():\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            {year} as Year,\n",
    "            '{country}' as Country,\n",
    "            COUNT(CASE WHEN NOC = '{country}' AND Year = {year} THEN Event END) as Medals_host,\n",
    "            COUNT(CASE WHEN NOC = '{country}' AND Year = {year-4} THEN Event END) as Medals_nothost1,\n",
    "            COUNT(CASE WHEN NOC = '{country}' AND Year = {year-8} THEN Event END) as Medals_nothost2,\n",
    "            COUNT(CASE WHEN NOC = '{country}' AND Year = {year+4} THEN Event END) as Medals_nothost3,\n",
    "            COUNT(CASE WHEN NOC = '{country}' AND Year = {year+8} THEN Event END) as Medals_nothost4\n",
    "        FROM medals\n",
    "    \"\"\"\n",
    "    result = spark.sql(query)\n",
    "    results.append(result)\n",
    "\n",
    "# Combine all results into one DataFrame\n",
    "final_df = results[0]\n",
    "for df in results[1:]:\n",
    "    final_df = final_df.union(df)\n",
    "\n",
    "# Add a new column to calculate the percentage increase in medals won during the host period compared to the maximum number of medals won during the non-host periods\n",
    "final_df = final_df.withColumn(\n",
    "    \"Medals_bigger%\",\n",
    "    (col(\"Medals_host\") - greatest(\"Medals_nothost1\", \"Medals_nothost2\", \"Medals_nothost3\", \"Medals_nothost4\"))\n",
    "    / col(\"Medals_host\") * 100\n",
    ")\n",
    "\n",
    "final_df.show()\n",
    "# Write EDA4 results to file\n",
    "final_df.write.csv(\"E:/hku/cloud cluster/ex4/output/eda4_host_country_medals.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference:\n",
    "In most countries hosting the Olympics, the host nation effect is quite evident, generally resulting in a performance increase of over 30%. However, the 1976, 2012, and 2016 Olympics are exceptions to this trend. Various factors could contribute to these anomalies, such as the reduction in the number of events during the 1970s due to the Cold War between the US and the Soviet Union.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the Spark Jobs\n",
    "\n",
    "Based on the provided code and the parsed physical plan, we can identify multiple Spark jobs. Specifically, we have 3 main tasks:\n",
    "\n",
    "1. Filtering records with medals.\n",
    "2. Calculating the number of medals won by host countries during the host period and the non-host periods.\n",
    "3. Adding a new column to show the percentage increase in medals won during the host period.\n",
    "\n",
    "Detailed Analysis of the Most Critical Spark Job\n",
    "\n",
    "Let's assume that calculating the number of medals won by host countries during the host period and non-host periods is the most critical Spark job. Here's a detailed analysis of this job:\n",
    "\n",
    "First Stage:\n",
    "- Operation: `filter(col(\"Medal\") != 'NA')`\n",
    "- Description: This operation filters out rows where the Medal column is 'NA', leaving only records with valid medal entries.\n",
    "- Shuffle Event: This operation does not involve a shuffle as it is a simple filter operation.\n",
    "\n",
    "Second Stage:\n",
    "- Operation: `spark.sql(query)`\n",
    "- Description: For each host year and country, a SQL query is executed to count the number of medals won during the host period and two previous and two subsequent Olympics.\n",
    "- Shuffle Event: This stage involves a shuffle because the `COUNT` operations and conditions on `NOC` and `Year` require data to be redistributed across the cluster to ensure correct grouping and counting.\n",
    "\n",
    "Third Stage:\n",
    "- Operation: `union(df)`\n",
    "- Description: This operation combines the results of the individual SQL queries into one DataFrame.\n",
    "- Shuffle Event: This stage involves a shuffle to merge the different partitions of each individual DataFrame into a single cohesive DataFrame.\n",
    "\n",
    "Fourth Stage:\n",
    "- Operation: `withColumn(\"Medals_bigger%\", ...)`\n",
    "- Description: This operation adds a new column calculating the percentage increase in medals won during the host period compared to the maximum number of medals won during the non-host periods.\n",
    "- Shuffle Event: This operation may trigger a shuffle if it involves repartitioning the data for the new column calculation.\n",
    "\n",
    "Summary Paragraph\n",
    "\n",
    "The critical Spark job in this analysis calculates the number of medals won by host countries during their host period and compares it with the two previous and two subsequent Olympics. This job involves filtering the data, executing multiple SQL queries for counting medals, and combining the results into a single DataFrame. Key operations like `spark.sql` and `union` trigger shuffle events due to the need for data redistribution and merging of partitions. Finally, a new column is added to show the percentage increase in medals won during the host period, providing insights into the performance boost for host countries. Understanding these stages helps optimize performance and ensures efficient data processing in PySpark for this exploratory data analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
